{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06a6173a-9469-4876-b330-5e528a053ee8",
   "metadata": {},
   "source": [
    "# Clasificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b7e50b-6a0f-43a2-814c-058bd4fb75a7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0c79022a-b84f-4221-b78f-34ebb268abef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lopez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lopez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Librerías generales\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Datasets\n",
    "from sklearn.datasets import load_iris, load_digits, load_breast_cancer, fetch_openml\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Modelos\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Preprocesamiento\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Procesamiento para el Email Dataset\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n",
    "\n",
    "# Gráficas\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9b4656-b60f-4e7d-bbe8-a7173a51f35e",
   "metadata": {},
   "source": [
    "## Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa9eacd-8044-4a5d-9568-83c11098a812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0c68ed5-6071-44c5-8a1e-4aa35b15640b",
   "metadata": {},
   "source": [
    "### Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "488e3fd2-327c-432f-ad1d-bd8889e60d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "# Guardamos en un Dataframe\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Separamos etiquetas\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Separamos en conjuntos de entrenamiento y pruebas\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Escalamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86729f3-3dfe-4752-9e80-c729ff8357f7",
   "metadata": {},
   "source": [
    "#### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "70462554-c1d9-42b6-be28-fef15ba8f868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Precision: 0.9023569023569025\n",
      "Recall: 0.9\n",
      "F1-Score: 0.8997493734335839\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo\n",
    "model = LinearSVC(random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones con el conjunto de pruebas\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "# Precision\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted')}\")\n",
    "\n",
    "# Recall\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted')}\")\n",
    "\n",
    "# F1-Score\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred, average='weighted')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f3fa1e-fbc7-4895-bf83-f08e796201d7",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c7d52011-806d-4e4c-bad9-263985b1fe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n",
      "Precision: 0.9696969696969696\n",
      "Recall: 0.9666666666666667\n",
      "F1-Score: 0.9665831244778613\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo\n",
    "model = MLPClassifier(hidden_layer_sizes=(50, 25), \n",
    "                          max_iter=500, activation='relu', random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones con el conjunto de pruebas\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "# Precision\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted')}\")\n",
    "\n",
    "# Recall\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted')}\")\n",
    "\n",
    "# F1-Score\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred, average='weighted')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d092f385-0ceb-46f0-9c97-2970e887acbb",
   "metadata": {},
   "source": [
    "### Digits Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1f69b8fb-dfa6-43e2-b1ea-aca0cd253f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "# Guardamos en un Dataframe\n",
    "df = pd.DataFrame(data=digits.data, columns=digits.feature_names)\n",
    "\n",
    "# Separamos etiquetasAC\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Separamos en conjuntos de entrenamiento y pruebas\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Escalamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bf5e28-f708-44e5-a728-5de1b506f71c",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2b792009-3616-4457-aa0a-802a435cc639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8305555555555556\n",
      "Precision: 0.8366671488637865\n",
      "Recall: 0.8305555555555556\n",
      "F1-Score: 0.8290715678437479\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo\n",
    "model = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones con el conjunto de pruebas\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "# Precision\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted')}\")\n",
    "\n",
    "# Recall\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted')}\")\n",
    "\n",
    "# F1-Score\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred, average='weighted')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1163a0a0-694c-4800-b56e-c5e492c40646",
   "metadata": {},
   "source": [
    "### Breast Cancer Wisconsin Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e4d2ffea-bb8d-42c5-980b-f38ce124d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Guardamos en un Dataframe\n",
    "df = pd.DataFrame(data=cancer.data, columns=cancer.feature_names)\n",
    "\n",
    "# Separamos etiquetas\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# Separamos en conjuntos de entrenamiento y pruebas\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Escalamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ae0b3a-a551-43aa-86aa-7c5175151f39",
   "metadata": {},
   "source": [
    "#### NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "60a65367-492e-467b-a941-71d475fefc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9385964912280702\n",
      "Precision: 0.9390013495276655\n",
      "Recall: 0.9385964912280702\n",
      "F1-Score: 0.9380859556298152\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo\n",
    "model = NuSVC(random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones con el conjunto de pruebas\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "# Precision\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted')}\")\n",
    "\n",
    "# Recall\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted')}\")\n",
    "\n",
    "# F1-Score\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred, average='weighted')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03e5225-6881-44ed-a1ea-98bcc3983fa2",
   "metadata": {},
   "source": [
    "### Titanic ML Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "56b05174-c804-4b58-8352-36e220fc92c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos en un Dataframe\n",
    "df = kagglehub.dataset_load(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"yasserh/titanic-dataset\",\n",
    "  \"Titanic-Dataset.csv\",\n",
    ")\n",
    "\n",
    "# Visualización del Dataset\n",
    "# print(df)\n",
    "\n",
    "# Eliminamos ID y Ticket, no aportan nada en la predicción\n",
    "df.drop(columns=[\"PassengerId\", \"Ticket\"], inplace=True)\n",
    "\n",
    "# Checamos si hay datos nulos\n",
    "# df.isnull().sum()\n",
    "\n",
    "# Llenamos Embarked con el valor más repetido (moda)\n",
    "df[\"Embarked\"] = df[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0])\n",
    "\n",
    "# Llenamos Age con la mediana de edades\n",
    "df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median())\n",
    "\n",
    "# Nueva columna que reemplaza a Cabin con Has_Cabin\n",
    "df[\"Has_Cabin\"] = df[\"Cabin\"].notnull().astype(int)\n",
    "df.drop(columns=[\"Cabin\"], inplace=True)\n",
    "\n",
    "# Nueva columna que reemplaza a Name con Title\n",
    "df[\"Title\"] = df[\"Name\"].apply(lambda x: x.split(\", \")[1].split(\".\")[0].strip())\n",
    "df.drop(columns=[\"Name\"], inplace=True)\n",
    "df[\"Title\"] = df[\"Title\"].replace(['Lady', 'the Countess','Capt','Col','Don','Dr',\n",
    "                                   'Major','Rev','Sir','Jonkheer','Dona'], 'Rare')\n",
    "df[\"Title\"] = df[\"Title\"].replace('Mlle', 'Miss')\n",
    "df[\"Title\"] = df[\"Title\"].replace('Ms', 'Miss')\n",
    "df[\"Title\"] = df[\"Title\"].replace('Mme', 'Mrs')\n",
    "\n",
    "# Aplicamos Encode manual a la columna Sex\n",
    "sex_map = {\"male\": 1, \"female\": 0}\n",
    "df[\"Sex\"] = df[\"Sex\"].map(sex_map)\n",
    "\n",
    "# Aplicamos One-Hot Encoding a las columnas Title y Embarked\n",
    "df = pd.get_dummies(df, columns=['Title', 'Embarked'], drop_first=True)\n",
    "\n",
    "# Dataset limpio\n",
    "# print(df)\n",
    "\n",
    "# Separamos etiquetas\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "# Separamos en conjuntos de entrenamiento y pruebas\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Escalamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577c50c5-0385-4e27-86aa-a42a11dfb6ef",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a6040d7e-5e8a-46fb-a627-d74531b3c6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8212290502793296\n",
      "Precision: 0.7846153846153846\n",
      "Recall: 0.7391304347826086\n",
      "F1-Score: 0.7611940298507462\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones con el conjunto de pruebas\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "# Precision\n",
    "print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "\n",
    "# Recall\n",
    "print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "\n",
    "# F1-Score\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf719313-a490-425b-909b-f85d7909f750",
   "metadata": {},
   "source": [
    "#### GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a395043b-8323-4308-bee0-2a442c2a0054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7932960893854749\n",
      "Precision: 0.7424242424242424\n",
      "Recall: 0.7101449275362319\n",
      "F1-Score: 0.725925925925926\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "    max_depth=1, random_state=0)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones con el conjunto de pruebas\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "# Precision\n",
    "print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "\n",
    "# Recall\n",
    "print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "\n",
    "# F1-Score\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dfc750-e05b-46ef-a689-36e1f8aaa15a",
   "metadata": {},
   "source": [
    "### MNIST Handwritten Digits Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5b4780ca-1be9-4bb9-a9d1-d8d7a096e8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el Dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Redimensionamos los datos para que DecisionTree los acepte\n",
    "X_train = X_train.reshape(X_train.shape[0], -1) / 255.0\n",
    "X_test = X_test.reshape(X_test.shape[0], -1) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b650d322-dd61-4ac9-a812-adbc93d8c142",
   "metadata": {},
   "source": [
    "#### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7357d07c-709e-46e3-8e7a-4290707328f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8813\n",
      "Precision: 0.8810354798739223\n",
      "Recall: 0.8813\n",
      "F1-Score: 0.8810517484718479\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo\n",
    "model = DecisionTreeClassifier(max_depth=15, min_samples_leaf=5, \n",
    "                               random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones con el conjunto de pruebas\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "# Precision\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted')}\")\n",
    "\n",
    "# Recall\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted')}\")\n",
    "\n",
    "# F1-Score\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred, average='weighted')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b349795-33c9-428a-b148-888aae016577",
   "metadata": {},
   "source": [
    "### Spam Vs. Ham Email Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3b8428db-7033-4404-94e6-2bd39f9446fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PK\u0003\u0004-\u0000fhnXdî<Ùÿÿÿÿÿÿÿÿ\u0014\u0000\u0014\u0000spam_Emails_data.csv\u0001\u0000\u0010\u0000;ËQ\u0015\u0000\u0000\u0000\u0000ðÈ¬\u0006\u0000\u0000\u0000\u0000ì½ËìH\u001d",
      "¸¯\u0000S}»E²ngVufuçffÉ=¿À\u0000»[8\u0000ÃÅÃ=<\u0016³âpÈ¦pÑáÌó\u0016©üùÑsTÍ\u0000¸{Ä{ãfKsX]áîÁ`¦o=ªÖ¸Ò7ßOþizø½k¿ÿî\u0014øn?8ù¿Ø5b\u0017b:ø\"v~?ÜT]7\u0015S  \\\n",
      "0       ÞµÅÇ~uØ_ð",
      ";w¢\u001aâ¹¨ý.t¾{\u0019µöÅØÇN.)]SFWÔam\f",
      "£...                                                                                                                                                               \n",
      "1                ÁïÝä\u000b",
      "¹¾òEé.ø¢O",
      "ëö¾É¶wã\u0018Nòm\u0018ª¹ÁÅòïê¢                                                                                                                                                               \n",
      "2       cåÆa\u000e\u0007×\u001c",
      "åQC]\u000fáù9tû×¸¡õ]p]QÍSãñZ\u0003~Ã[°|[...                                                                                                                                                               \n",
      "3       U\u0014vèäoáWáG¹j.äsÜÉ5\u001d",
      "ho\u0017*¹-\u0014\u000e/XÍ¦¾èòu·ìêã0...                                                                                                                                                               \n",
      "4          CL\u0010]\u001f\u001føÇYæè³»Z¯.½Ði»ZÅß\u001f~.ï\u0006>µ\u0011Ö;ÿ+YÇ D\"                                                                                                                                                               \n",
      "...                                                   ...                                                                                                                                                               \n",
      "761177  ÔÀø\u0016õ°\u0012$\u001b6¥ì7¶\u0005¬^ÉMZk~Xú\u001b\u0014õ\u001e",
      "\u001fÉ\u0003\u00045ð\\t¦¾&ñ...                                                                                                                                                               \n",
      "761178                             ¡Ï4×E\u0011\u001a]?ðI>åã)¾Ù{··                                                                                                                                                               \n",
      "761179           \u000fÁÚa? ß@À0Êñ7ÖÒ\u0014<\u0010Ûÿë³ý¬+\u0002¹²\u001bø½\u0003\u001c",
      "NÚ\u0015÷K\u0001Ì                                                                                                                                                               \n",
      "761180  ·l_±nó'/»>÷úÍ:Ò#×ùµsQWrÌ\u0007é\u0002jØ\u000f7ÖSqÕªäx¨U...                                                                                                                                                               \n",
      "761181  ;êîRÔ\u0007cÉ%\u001a\u001b¶£\u0017»9) \u0017ò4ïxpÔ8\u0001ÍD4Åf~=#®\\SV...                                                                                                                                                               \n",
      "\n",
      "                                                 ZwôÅÁ\u000fÅX  \n",
      "0                                                    None  \n",
      "1                                                    None  \n",
      "2                                                    None  \n",
      "3                                                    None  \n",
      "4       \u0016åö6Öòþ¼{t;/²äÂuGUrlQ@5É­«?þ$Rª'HÕ(7I~...  \n",
      "...                                                   ...  \n",
      "761177                                               None  \n",
      "761178                                               None  \n",
      "761179  \u0005ïÕ:^ªÅRT«{\"=X£õì²³_\u0015:ím|Þ<BaóëÅÑ\u0003ÛÀóí²·°...  \n",
      "761180                                               None  \n",
      "761181  @\u0012CTå{\u001bp\u0014õp4\u0006ÍÉÓû;BO¹m\u0010æ´QþÞûÊ\\t¨Û$Q\u0006wRþÞ...  \n",
      "\n",
      "[761182 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Importar Dataset\n",
    "df = kagglehub.dataset_load(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"meruvulikith/190k-spam-ham-email-dataset-for-classification\",\n",
    "  \"spam_Emails_data.csv\",\n",
    "  pandas_kwargs={\n",
    "      'encoding': 'latin-1',\n",
    "      'engine': 'python',\n",
    "      'on_bad_lines': 'skip'\n",
    "  }\n",
    ")\n",
    "\n",
    "# Imprimimos el Dataset\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2234803-8240-4100-8fc5-0792a4b1c216",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75f148b-d579-4318-85cf-e4bb54860aae",
   "metadata": {},
   "source": [
    "#### NaiveBayes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
